{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime Webscraping and Database Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection: Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "import pyodbc\n",
    "import re\n",
    "\n",
    "print('The necessary libraries needed for the project are now loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of chrome driver\n",
    "driver_path = 'C:/Users/medma/Documents/Data Science/chromedriver_win32/chromedriver.exe'\n",
    "#location of brave browser\n",
    "brave_path = 'C:/Program Files (x86)/BraveSoftware/Brave-Browser/Application/brave.exe'\n",
    "\n",
    "#give webdriver the brave browser location\n",
    "option = webdriver.ChromeOptions()\n",
    "option.binary_location = brave_path\n",
    "\n",
    "#open a phantom version of the brave browser\n",
    "browser = webdriver.Chrome(executable_path=driver_path, chrome_options=option)\n",
    "\n",
    "#makes Selenium wait for 5 seconds before throwing an exception that it cannot find an element on the page loaded into the browser\n",
    "wait = WebDriverWait(browser, 5)\n",
    "\n",
    "print('Brave is built on open-source Chromium code, so a chromedriver can be used to open a phantom Brave browser.' '\\n'\n",
    "      'The paths for the driver and browser are stored, and a phantom Brave browser is now opened.' '\\n'\n",
    "      'The WebDriverWait method of Selenium, which will wait for 5 seconds before throwing an exception, is shortened and stored for later use.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for page in range (0, 100, 50):\n",
    "    browser.get('https://myanimelist.net/topanime.php?type=bypopularity&limit=' + str (page))\n",
    "    #find all elements in page by \"CSS Selector's element\" and save them in variable \"link\"\n",
    "    link = browser.find_elements(By.CSS_SELECTOR, 'div[class=\"detail\"] h3 a')\n",
    "    #for all elements in link append the href attribute and save them in links\n",
    "    for item in link:\n",
    "        links.append(item.get_attribute('href'))\n",
    "\n",
    "print('Selenium is now scraping the url links of the top 100 popular anime, 50 animes at a time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prankings = []\n",
    "rankings = []\n",
    "scores = []\n",
    "titles = []\n",
    "genres = []\n",
    "episodes = []\n",
    "studios = []\n",
    "durations = []\n",
    "ratings = []\n",
    "\n",
    "for item_link in links:\n",
    "    browser.get(item_link)\n",
    "    #wait until the CSS selected element is visible and save the element in 'popularity'\n",
    "    pranking = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'span[class=\"numbers popularity\"]')))\n",
    "    #wait until the CSS selected element is visible and save the element in 'ranking'\n",
    "    ranking = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'span[class=\"numbers ranked\"]')))\n",
    "    #wait until the CSS selected element is visible and save the element in 'score'\n",
    "    score = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div[class*=\"score-label\"]')))\n",
    "    #wait until the CSS selected element is visible and save the text in 'title'\n",
    "    title = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div[class=\"h1-title\"]')))\n",
    "    #wait until the xpath selected text is visible and save the texts in 'genre'\n",
    "    genre = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[contains(text(), \"Genres\")]/parent::div')))\n",
    "    #wait until the xpath selected text is visible and save the text in 'episode'\n",
    "    episode = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[contains(text(), \"Episodes\")]/parent::div')))\n",
    "    #wait until the xpath selected text is visible and save the text in 'studio'\n",
    "    studio = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[contains(text(), \"Studios\")]/parent::div')))\n",
    "    #wait until the xpath selected text is visible and save the text in 'duration'\n",
    "    duration = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[contains(text(), \"Duration\")]/parent::div')))\n",
    "    #wait until the xpath selected text is visible and save the text in 'rating'\n",
    "    rating = wait.until(EC.visibility_of_element_located((By.XPATH, '//*[contains(text(), \"Rating\")]/parent::div')))\n",
    "    \n",
    "    #for all elements in title, rating, and genre, save the texts in the lists titles, ratings, and genres\n",
    "    prankings.append(pranking.text)\n",
    "    rankings.append(ranking.text)\n",
    "    scores.append(score.text)\n",
    "    titles.append(title.text)\n",
    "    genres.append(genre.text)\n",
    "    episodes.append(episode.text)\n",
    "    studios.append(studio.text)\n",
    "    durations.append(duration.text)\n",
    "    ratings.append(rating.text)\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "browser.quit()\n",
    "\n",
    "print('Selenium is now scraping all of the top 100 popular anime webpages for specified information one anime at a time.' '\\n'\n",
    "      'Once that process concludes, Selenium will make the phantom Brave browser wait 2 seconds and then close the browser.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {'Popularity Rankings': prankings, 'Rankings': rankings, 'Scores': scores, 'Titles': titles, 'Genres': genres, \n",
    "           'Episodes': episodes, 'Studios': studios, 'Durations': durations, 'Ratings': ratings}\n",
    "df = pd.DataFrame(data=my_data)\n",
    "\n",
    "print('A dictionary is created that stores the lists for Popularity Rankings, Rankings, Scores, Titles, Genres, Episodes, Studios,' '\\n'\n",
    "      ' Durations, and Ratings. That dictionary is then stored into a dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the dataframe for unique values\n",
    "for i in df.columns:\n",
    "    print('unique values in \"{}\":\\n'.format(i),df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda x, regex, and loops for data cleaning \n",
    "\n",
    "#split away column names from column values in the first seven columns using lamba x: x.split\n",
    "df['Popularity Rankings'] = df['Popularity Rankings'].apply(lambda x: x.split(' #')[1])\n",
    "df['Rankings'] = df['Rankings'].apply(lambda x: x.split(' #')[1])\n",
    "df['Genres'] = df['Genres'].apply(lambda x: x.split(': ')[1])\n",
    "df['Episodes'] = df['Episodes'].apply(lambda x: x.split(': ')[1])\n",
    "df['Studios'] = df['Studios'].apply(lambda x: x.split(': ')[1])\n",
    "\n",
    "#standardize the Durations column to minutes using regular expressions\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([0-9]{1}\\s[a-z]{2}.\\s[46]).*$', value='106', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([0-9]{1}\\s[a-z]{2}.\\s[10]).*$', value='130', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([0-9]{1}\\s[a-z]{2}.\\s[4]).*$', value='124', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([0-9]{1}\\s[a-z]{2}.\\s[13]).*$', value='133', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([0-9]{1}\\s[a-z]{2}.\\s[59]).*$', value='119', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([23]).*$', value='23', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([24]).*$', value='24', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([25]).*$', value='22', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([22]).*$', value='22', regex=True)\n",
    "df['Durations'] = df['Durations'].replace(to_replace='^.*([28]).*$', value='28', regex=True)\n",
    "\n",
    "#standardize the Ratings column and clean up remaining minor issues using a loop\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i,5]=='Unknown':\n",
    "        df.iloc[i,5]='984'\n",
    "    if df.iloc[i,6] in ['Walt Disney Studios, GKIDS', 'Licensors: Walt Disney Studios']:\n",
    "        df.iloc[i,6]='Studio Ghibli'\n",
    "    if df.iloc[i,8]=='Rating: R - 17+ (violence & profanity)':\n",
    "        df.iloc[i,8]='R-17+'\n",
    "    if df.iloc[i,8]=='Rating: PG-13 - Teens 13 or older':\n",
    "        df.iloc[i,8]='PG-13'\n",
    "    if df.iloc[i,8]=='Rating: R+ - Mild Nudity':\n",
    "        df.iloc[i,8]='R+'\n",
    "    if df.iloc[i,8]=='Rating: PG - Children':\n",
    "        df.iloc[i,8]='PG'\n",
    "    if df.iloc[i,8]=='Rating: G - All Ages':\n",
    "        df.iloc[i,8]='G'\n",
    "\n",
    "#check the corrections\n",
    "df.head(10)\n",
    "\n",
    "print('There are a number of ways that the df dataframe can be cleaned. Three such ways include the use of lambda x, regex, and loops,' '\\n'\n",
    "      ' which have now all been used to clean parts of the df dataframe. The dataframe is now ready for data visualization.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "\n",
    "print('Before visualizing the data, the data types for all the columns should be checked for incorrectness.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the integer and float data into their corresponding data types\n",
    "df['Popularity Rankings'] = df['Popularity Rankings'].astype(int)\n",
    "df['Rankings'] = df['Rankings'].astype(int)\n",
    "df['Scores'] = df['Scores'].astype(float)\n",
    "df['Episodes'] = df['Episodes'].astype(int)\n",
    "df['Durations'] = df['Durations'].astype(int)\n",
    "\n",
    "#check the conversions\n",
    "df.dtypes\n",
    "\n",
    "print('Several data type corrections for columns are done and checked.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_join = ','.join(df['Genres'])\n",
    "genre_join\n",
    "\n",
    "print('All of the genres of all the animes are joined together in one huge series.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_split = genre_join.split(',')\n",
    "genre_split\n",
    "\n",
    "print('The genre values are then split up by commas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for x in genre_split:\n",
    "    result.append(x.strip())\n",
    "result\n",
    "\n",
    "print('Consistent spacing is created through the stripping of leading and trailing whitespaces.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(result)\n",
    "\n",
    "print('The genres are saved in a new series.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check available styles\n",
    "print(plt.style.available)\n",
    "\n",
    "# set the preferred style\n",
    "style.use('ggplot')\n",
    "\n",
    "print('The matplotlib library has many styles to choose from for visualization.' '\\n' \n",
    "      ' Ggplot is a good choice, especially for those familiar with the software R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get the value counts for each genre\n",
    "mydata = []\n",
    "for y in data.value_counts():\n",
    "    mydata.append(y)\n",
    "    \n",
    "#get the labels for the value counts\n",
    "labels = []\n",
    "for z in data.value_counts().index.tolist():\n",
    "    labels.append(z)\n",
    "    \n",
    "#create a dataframe for the counts and labels of the counts\n",
    "newdf = pd.DataFrame(labels, mydata)\n",
    "\n",
    "#create a plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Most Popular Genre')\n",
    "plt.xlabel(\"Genres\")\n",
    "plt.ylabel(\"Total Number of Times Genre is Present in Anime Data\")\n",
    "sns.barplot(data=newdf, x=mydata, y=labels)\n",
    "\n",
    "print('The value counts for each genre, along with their respective labels, are saved in a new dataframe.' '\\n'\n",
    "      ' A barplot is created to illustrate the most popular genres, with Action being the most popular genre.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.Series(df['Ratings'])\n",
    "rating\n",
    "\n",
    "print('Ratings values are ready to be visualized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the value counts for each genre\n",
    "ratings = []\n",
    "for y in rating.value_counts():\n",
    "    ratings.append(y)\n",
    "    \n",
    "#get the labels for the value counts\n",
    "labels2 = []\n",
    "for z in rating.value_counts().index.tolist():\n",
    "    labels2.append(z)\n",
    "    \n",
    "#create a dataframe for the counts and labels of the counts\n",
    "newdf2 = pd.DataFrame(labels2, ratings)\n",
    "\n",
    "#create a plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Most Popular Rating')\n",
    "plt.xlabel(\"Ratings\")\n",
    "plt.ylabel(\"Total Number of Times Rating is Present in Anime Data\")\n",
    "sns.barplot(data=newdf2, x=labels2, y=ratings)\n",
    "\n",
    "print('The most popular rating by a decent margin is PG-13. This is unsurprising since most movie studios see PG-13 rated movies as the most profitable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for driver in pyodbc.drivers():\n",
    "    print(driver)\n",
    "    \n",
    "print('Loop through all pyodbc drivers to see which drivers are available for use.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'LAPTOP-51U9EL13\\SQLEXPRESS' \n",
    "database = 'master' \n",
    "\n",
    "print('The server and database are now defined. A new database will be created, so the master database is used for now.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server}; \\\n",
    "    SERVER='+ server +'; \\\n",
    "    DATABASE='+ database +';\\\n",
    "    Trusted_Connection=yes;',\n",
    "    autocommit=True\n",
    ")\n",
    "\n",
    "print('The connection string is defined to connect to Microsoft SSMS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"DROP DATABASE if exists MyAnimeList\")\n",
    "cursor.execute(\"CREATE DATABASE MyAnimeList\")\n",
    "\n",
    "print('A connection cursor is created to manipulate the master database. It is used to created a new database for myanimelist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"sp_databases\")\n",
    "\n",
    "for db in cursor:\n",
    "    print(db)\n",
    "    \n",
    "print('All the databases in Microsoft SSMS are listed to check that the anime database has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_database = \"MyAnimeList\"\n",
    "conn_2 = pyodbc.connect(\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server}; \\\n",
    "    SERVER='+ server +'; \\\n",
    "    DATABASE='+ anime_database +';\\\n",
    "    Trusted_Connection=yes;',\n",
    "    autocommit=True\n",
    ")\n",
    "\n",
    "cursor_2 = conn_2.cursor()\n",
    "\n",
    "print('A connection string for the new database is created, along with a new cursor for manipulating that database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_2.execute(\"DROP TABLE if exists top100popularanime\")\n",
    "cursor_2.execute('''CREATE TABLE top100popularanime\n",
    "              ([Popularity Rankings] int,\n",
    "               Rankings int,\n",
    "               Scores float,\n",
    "               Titles varchar(255), \n",
    "               Genres varchar(255), \n",
    "               Episodes varchar(255), \n",
    "               Studios varchar(255),\n",
    "               Durations varchar(255), \n",
    "               Ratings varchar(255))\n",
    "\n",
    "''')\n",
    "\n",
    "conn_2.commit()\n",
    "\n",
    "print('A table is created for insertion of the anime dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = pd.DataFrame.to_numpy(df)\n",
    "\n",
    "print('An array of the values of the anime dataframe is created for insertion into the newly created anime table.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the insert query\n",
    "insert_query = '''INSERT INTO top100popularanime ([Popularity Rankings], Rankings, Scores, Titles, Genres, Episodes, Studios, Durations, Ratings) \n",
    "                  VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?);'''\n",
    "\n",
    "#loop through each row in the dataframe\n",
    "for row in array:\n",
    "    #define the values to insert\n",
    "    values = (row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8])\n",
    "    \n",
    "    #insert the data into the database\n",
    "    cursor_2.execute(insert_query, values)\n",
    "    \n",
    "#commit the inserts\n",
    "conn_2.commit()\n",
    "\n",
    "#grab all the rows in the myanimelist table\n",
    "cursor_2.execute ('SELECT * FROM top100popularanime')\n",
    "\n",
    "#loop through the results\n",
    "for row in cursor_2:\n",
    "    print(row)\n",
    "    \n",
    "print('Now the top100popularanime table has all of the values from the anime dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topscores =  pd.DataFrame(cursor_2.execute(\"SELECT Scores \\\n",
    "                  FROM top100popularanime \\\n",
    "                  WHERE Scores >= 8 \\\n",
    "                  ORDER BY Scores DESC\"))\n",
    "topscoredtitles = pd.DataFrame(cursor_2.execute(\"SELECT Titles, Episodes, Studios \\\n",
    "                  FROM top100popularanime\"))\n",
    "\n",
    "top = pd.concat([topscores, topscoredtitles], axis=1)\n",
    "top.head(20)\n",
    "\n",
    "print('Here is apractice query on the top100popular anime table, followed by the creation of a dataframe for that query.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
